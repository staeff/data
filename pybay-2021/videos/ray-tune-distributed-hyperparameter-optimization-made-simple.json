{
  "description": "This talk was presented at PyBay2021 Food Truck Edition - 6th annual Bay Area Regional Python conference. See pybay.com for more details about PyBay and click SHOW MORE for more information about this talk.\n\nDESCRIPTION\nIn this talk, we will overview standard methods for hyperparameter tuning: grid search, random search, and bayesian optimization. We will also showcase the cutting edge methods such as BOHB, BlendSearch and HyperSched. We will discuss the challenges of using diverse libraries and algorithms in order to experiment and implement cutting edge optimization. Then, we will showcase Ray Tune and its sklearn-wrapper, tune-sklearn, which present a unified API for distributed hyperparameter optimization and how simple tune-sklearn is to use and integrate within existing scikit-learn based pipelines.\n\nABOUT THE SPEAKER\nXiaowei was a software engineer at Google and Uber before joining Anyscale's ML team.\n\nSPONSOR ACKNOWLEDGEMENT\nThis and other PyBay2021 videos are made possible by our sponsors:\n- Carta https://carta.com\n- Anyscale https://anyscale.com\n- Goodrx https://goodrx.com\n- Nginx https://nginx.com\n- Bit.io https://bit.io\n\nEVENT PRODUCER ACKNOWLEDGEMENT\nThis community conference is produced by organizers of SF Python meetup and volunteers from around the SF Bay Area. See upcoming events here: https://sfpythonmeetup.com",
  "duration": 1509,
  "language": "eng",
  "recorded": "2021-10-09",
  "speakers": [
    "Xiaowei Jiang"
  ],
  "thumbnail_url": "https://i.ytimg.com/vi_webp/KgYZtlbFYXE/maxresdefault.webp",
  "title": "Ray Tune: Distributed Hyperparameter Optimization Made Simple",
  "videos": [
    {
      "type": "youtube",
      "url": "https://www.youtube.com/watch?v=KgYZtlbFYXE"
    }
  ]
}